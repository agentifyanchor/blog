
[{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/","section":"Agentify Anchor","summary":"","title":"Agentify Anchor","type":"page"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/authentication/","section":"Tags","summary":"","title":"Authentication","type":"tags"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/authorization/","section":"Tags","summary":"","title":"Authorization","type":"tags"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/azure-ad/","section":"Tags","summary":"","title":"Azure AD","type":"tags"},{"content":" üöÄ New Year\u0026rsquo;s Gift: Automating MCP Connections for Copilot Agents # First off, a huge shoutout to Tobias Maestrini, whose article Developing an MCP scenario with TypeScript (and GitHub sample) paved the way one month ago. It was the spark that got me curious: How can we create an MCP Server specifically for Copilot Agents?\nWhile building this, I discovered a major hurdle in how the Power Platform (which powers Copilot Studio) handles custom connectors. It doesn\u0026rsquo;t use a static Redirect URI. Instead, it generates a unique, dynamic one for every single connection!\nThis post details the journey of solving that problem using Dynamic Client Registration (DCR) and Microsoft Graph, creating a truly \u0026ldquo;plug-and-play\u0026rdquo; experience.\nüõë The Problem: Dynamic Redirect URIs # When you connect an MCP Server to Copilot Studio, the platform generates a unique Redirect URI via Azure API Management (APIM). It looks something like this:\nhttps://global.consent.azure-apim.net/redirect/mvp-5fholy-20moly-20mcp-20dcr-5fdfde809e1caf448f\nBreakdown of the URI:\nmvp-5f: The Publisher of the solution (URL encoded). holy-20moly...: The name of your custom connector. 5fdfde...: A unique ID (likely the connector or environment ID). Because this URI changes based on the environment and connector name, you can\u0026rsquo;t pre-register it in your Azure App Registration. If you try to log in, Azure AD blocks you with the dreaded Redirect URI Mismatch error.\nManual copy-pasting for every deployment? No thanks. We can do better.\nüí° The Solution: Automated DCR # We implemented an endpoint that intercepts the DCR request from the Power Platform and uses the Microsoft Graph API to update the Azure App Registration on the fly.\n1. The Permissions # The secret sauce is the Application.ReadWrite.All permission in Microsoft Entra ID.\nFigure 1: Granting the Application Permissions to allow self-modification.\nThis allows our MCP Server (running as a Service Principal) to say: \u0026ldquo;Hey Azure, add this new Redirect URI to my list of allowed URLs.\u0026rdquo;\n2. The Implementation # When Copilot Studio sends a registration request to our /oauth/register endpoint, we don\u0026rsquo;t just return static credentials. We:\nAuthenticate as the App itself (Client Credentials flow). Patch the App Registration via Graph API to include the new Redirect URI found in the request. Return the Client ID and Secret to Copilot. The result? The Redirect URI appears in the Azure Portal automatically!\nFigure 2: The dynamic URI automatically registered in Azure.\nüîß Technical \u0026ldquo;Gotchas\u0026rdquo; # It wasn\u0026rsquo;t all smooth sailing. Here are three critical fixes we implemented:\n‚ö†Ô∏è Replication Delay (The \u0026ldquo;Retry\u0026rdquo; Trick) # When the MCP Server updates the App Registration, the change in Azure AD takes a few seconds to propagate.\nSymptom: You see a \u0026ldquo;Redirect URI Mismatch\u0026rdquo; error on the first try. Solution: Just wait 5 seconds and click \u0026ldquo;Create\u0026rdquo; (or \u0026ldquo;Login\u0026rdquo;) again. It works automatically the second time because the URI is now valid. This is expected behavior with dynamic updates. AADSTS90009: The Scope Issue # When the Connector (Client ID X) tries to request a token for the MCP Server (Resource ID X), asking for a scope like api://\u0026lt;guid\u0026gt;/mcp fails if the Client and Resource are the same application. Fix: Use the format \u0026lt;App-ID-GUID\u0026gt;/.default.\nToken Validation: \u0026ldquo;Required Scope Not Found\u0026rdquo; # Once we fixed the scope, the Access Token no longer contained our custom \u0026quot;mcp\u0026quot; scope string. Fix: Instead of validating the scope string, we switched to validating the Audience (aud) claim. This is actually more secure‚Äîit ensures the token was issued specifically for your application.\nüéâ The Result # A confusing configuration process is now completely invisible. You just click \u0026ldquo;Connect\u0026rdquo; in Copilot Studio, and the green checkmark appears.\nFigure 3: Successful connection in Copilot Studio.\nAnd finally, the Agent in action, discovering SharePoint sites, listing their contents, and fetching items‚Äîall powered by MCP tools!\nFigure 4: The full discovery chain: Users -\u0026gt; Sites -\u0026gt; Lists -\u0026gt; Items.\nüéÅ Happy New Year! # I hope this helps you build amazing MCPs in 2026.\nüëâ Get the full code on GitHub\nHappy Coding!\n","date":"30 December 2025","externalUrl":null,"permalink":"/posts/2025-12-30-building-a-production-ready-mcp-server-for-copilot-with-dynamic-client-registration/","section":"Posts","summary":"","title":"Building a Production-Ready MCP Server for Copilot with Dynamic Client Registration","type":"posts"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/copilot/","section":"Tags","summary":"","title":"Copilot","type":"tags"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/dynamic-client-registration/","section":"Tags","summary":"","title":"Dynamic Client Registration","type":"tags"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/graph-api/","section":"Tags","summary":"","title":"Graph API","type":"tags"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/identity/","section":"Tags","summary":"","title":"Identity","type":"tags"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/mcp/","section":"Tags","summary":"","title":"MCP","type":"tags"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/categories/mcp/","section":"Categories","summary":"","title":"MCP","type":"categories"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/microsoft-graph/","section":"Tags","summary":"","title":"Microsoft Graph","type":"tags"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/oauth2/","section":"Tags","summary":"","title":"OAuth2","type":"tags"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/oidc/","section":"Tags","summary":"","title":"OIDC","type":"tags"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"30 December 2025","externalUrl":null,"permalink":"/tags/typescript/","section":"Tags","summary":"","title":"TypeScript","type":"tags"},{"content":" Complete Generative AI Learning Resource for Beginners # You are inetrested by Generative AI and you dont know from where you can start or looking to refine your your expertise, we‚Äôve got you covered.\nI am excited to share with you a great comprehensive learning resource provided by Microsoft that takes you from the fundamentals of Generative AI like building your own, propmt concept, fine tuning to sophisticated concepts like Retrieval-Augmented Generation (RAG), securing generative AI applications, and LLMOps.\nThis resource offers a step-by-step approach, code samples and vedios accessible while preparing you for real-world challenges.\nWhat‚Äôs inside? # 21 lessons labeled \u0026ldquo;Learn\u0026rdquo; or \u0026ldquo;Build\u0026rdquo; Python and TypeScript code examples to explain concepts Interactive exercises and the possibility to meet other classmates and get support through an official Discord server Start learning today! # Explore the full course and GitHub repository here: Generative AI for Beginners\nAdditionally, if you\u0026rsquo;re interested in exploring Machine Learning (ML) and MLOps, Microsoft offers a fantastic path to get started. Check out the ML for Beginners GitHub repository for more hands-on resources to deepen your understanding of ML and MLOps.\n","date":"21 January 2025","externalUrl":null,"permalink":"/posts/2025-01-21-a-complete--generative-ai-learning-resource-for-beginners-and-beyond/","section":"Posts","summary":"","title":"A Complete  Generative AI Learning Resource for Beginners and Beyond","type":"posts"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/aiapplications/","section":"Tags","summary":"","title":"AIApplications","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/aidevelopment/","section":"Tags","summary":"","title":"AIDevelopment","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/aiforbeginners/","section":"Tags","summary":"","title":"AIforBeginners","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/aiforbusiness/","section":"Tags","summary":"","title":"AIForBusiness","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/aimodels/","section":"Tags","summary":"","title":"AIModels","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/airesources/","section":"Tags","summary":"","title":"AIResources","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/aitraining/","section":"Tags","summary":"","title":"AITraining","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/artificialintelligence/","section":"Tags","summary":"","title":"ArtificialIntelligence","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/codingforai/","section":"Tags","summary":"","title":"CodingForAI","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/deeplearning/","section":"Tags","summary":"","title":"DeepLearning","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/generativeai/","section":"Tags","summary":"","title":"GenerativeAI","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/github/","section":"Tags","summary":"","title":"GitHub","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/innovationinai/","section":"Tags","summary":"","title":"InnovationInAI","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/learnai/","section":"Tags","summary":"","title":"LearnAI","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/llmops/","section":"Tags","summary":"","title":"LLMOps","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/machinelearning/","section":"Tags","summary":"","title":"MachineLearning","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/rag/","section":"Tags","summary":"","title":"RAG","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/secureai/","section":"Tags","summary":"","title":"SecureAI","type":"tags"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/tags/techeducation/","section":"Tags","summary":"","title":"TechEducation","type":"tags"},{"content":"","date":"20 January 2025","externalUrl":null,"permalink":"/tags/agent/","section":"Tags","summary":"","title":"Agent","type":"tags"},{"content":"","date":"20 January 2025","externalUrl":null,"permalink":"/tags/bot/","section":"Tags","summary":"","title":"Bot","type":"tags"},{"content":"In this blog post, I will guide you through creating a bot-based message extension for Microsoft Teams, without the necessity of the Microsoft 365 Copilot license or waiting until joining the Microsoft 365 Developer Technology Adoption Program (TAP)\nWhile Microsoft 365 Copilot provides enhanced features for enterprise users, you can still build powerful bots using Ollama, a locally run model like Llama3.2, to handle natural language processing.\n1. Setting Up Ollama Locally Using Docker Compose # In this section, I‚Äôll walk you through setting up Ollama locally using Docker Compose. This step-by-step guide will show you how to run Ollama with the Llama3.2 model, providing you with a local environment to process natural language queries for your Microsoft Teams bot.\nMy approach to setting up a local environment is inspired by the n8n self-hosted AI starter kit.\nThe main idea behind was to separate the main Ollama service from the initialization service that pulls models.\ngraph TD A[Ollama_Main_API_Service] --\u003e|Port 11434| B[Ollama_Model_Server_Llama_Models] B --\u003e C[Ollama_Pull_Models_Service] C --\u003e D[Downloads_Models_llama3.2_llama2_nomic_embed_text] A --\u003e|Exposes_API| B C --\u003e|Depends_on| A C --\u003e|Downloads_Models| B style A fill:#f9f,stroke:#333,stroke-width:2px style B fill:#ccf,stroke:#333,stroke-width:2px style C fill:#cfc,stroke:#333,stroke-width:2px style D fill:#fcf,stroke:#333,stroke-width:2px The main Ollama (API service) runs the Ollama model server and exposes the API on port 11434.\nThe second instance (init-ollama) is responsible for pulling the models (e.g., llama3.2) when the container starts.\nThe steps to run environment is quite simple, download the Docker Compose YAML file and run:\ndocker compose --profile cpu up Note If you are interested to GPU you can upgrade this or inspiring from the n8n template 1.1 check model pulling # After a while, we can check our service by running the curl command:\ncurl -X GET http://localhost:11434/v1/models If the model(s) are available, we should get a response as shown below:\n1.2 check completions endpoint # After the model loads successfully, we can proceed with running some prompts:\ncurl -X POST http://localhost:11434/v1/chat/completions \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;model\u0026#34;: \u0026#34;llama3.2:latest\u0026#34;, \u0026#34;messages\u0026#34;: [{\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Hello, Ollama!\u0026#34;}] }\u0026#39; 2. Updating the LlamaModel.ts # After setting up Ollama, we will go through the necessary updates to the original LlamaModel.ts file.\nI‚Äôve overridden the completePrompt method to adjust the payload structure to properly interact with Ollama‚Äôs API endpoints.\nThe most important change is in the payload used to communicate with the service endpoint. I‚Äôve modified it from:\n{ input_data: { input_string: result.output, parameters: template.config.completion } } to use the right format\nconst adjustedPayload = { model: \u0026#34;llama3.2:latest\u0026#34;, // Use the correct model identifier prompt: result.output.map(msg =\u0026gt; msg.content).join(\u0026#39; \u0026#39;), // Flatten messages into a single prompt string max_tokens: template.config.completion.max_tokens || 50, temperature: template.config.completion.temperature || 0.7, //completion_type: \u0026#34;chat\u0026#34;, }; And instead of making the existing request:\nawait this._httpClient.post\u0026lt;{ output: string }\u0026gt;(this.options.endpoint, { input_data: { input_string: result.output, parameters: template.config.completion } }); I use my adjustedPayload\nawait this.llamaModel[\u0026#39;_httpClient\u0026#39;].post(this.llamaModel.options.endpoint, adjustedPayload); And that\u0026rsquo;s it! üòâ\n3. Integrating with Microsoft Teams Samples # To simplify my testing, I used the existing concept sample provided by the Microsoft Teams AI team.\nThis sample typically requires an Azure subscription and use Azure Open AI Studio to create a Llama model. However, in our case, we\u0026rsquo;re doing it for free üòÅ by using our local platform and updating the code to make it work seamlessly.\nTo start using LlamaModelLocal with your MS Teams agent, just download the file, add it to your project\u0026rsquo;s src directory, and import the new LlamaModelLocal instead of the original LlamaModel:\nimport { LlamaModelLocal } from \u0026#34;./oLlamaModel\u0026#34;; Next, replace ts const model = new LlamaModel with ts const model = new LlamaModelLocal Finally, define LLAMA_ENDPOINT in your .env file to point to v1/completions\nLLAMA_ENDPOINT= http://localhost:11434/v1/completions 4. Testing and Debugging with Microsoft Teams Developer Tools # Finally, we will be able to go through testing and debugging our bot using the Teams app test tool.\nWe can start debugging by simply hitting F5 or click start debugging in RUN menu in VsCode.\nNote: Make sure to run npm i or yarn i before starting debugging. And here we go! An instance of the Teams app test tool should open at http://localhost:some_port_number/.\nNow, let\u0026rsquo;s dive into testing our agent!\nSince I\u0026rsquo;ve enabled the logRequests feature and I\u0026rsquo;m running in debug mode, I have access to the secret word. Yes, I know it\u0026rsquo;s a bit like cheating, but I couldn\u0026rsquo;t resist üòá.\nBecause cost matters, this approach allows us to start developing a Microsoft Teams Agent using natural language processing locally with Ollama, without relying on Microsoft 365 Copilot licenses. It‚Äôs a cost-effective, easy-to-setup solution for building and testing Teams agents.\nDemo and Code Sources: # The complete source code used in this demo can be found in this GitHub repository.\nIn the next post, we‚Äôll explore how to create a custom engine agent, deploy it to Microsoft Teams, and use Dev Tunnel SDK to expose publicly our local Ollama endpoint to the internet.\nStay tuned! üëã\n","date":"20 January 2025","externalUrl":null,"permalink":"/posts/2025-01-20-building-a-free-bot-based-message-extension-for-microsoft-teams-without-microsoft-365-copilot-leveraging-ollama-with-llama32/","section":"Posts","summary":"","title":"Building a Free bot-based message extension agent for Microsoft Teams Without Microsoft 365 Copilot: Leveraging Ollama with Llama3.2","type":"posts"},{"content":"","date":"20 January 2025","externalUrl":null,"permalink":"/tags/docker/","section":"Tags","summary":"","title":"Docker","type":"tags"},{"content":"","date":"20 January 2025","externalUrl":null,"permalink":"/tags/llama3.2/","section":"Tags","summary":"","title":"Llama3.2","type":"tags"},{"content":"","date":"20 January 2025","externalUrl":null,"permalink":"/tags/m365/","section":"Tags","summary":"","title":"M365","type":"tags"},{"content":"","date":"20 January 2025","externalUrl":null,"permalink":"/tags/message-extension/","section":"Tags","summary":"","title":"Message Extension","type":"tags"},{"content":"","date":"20 January 2025","externalUrl":null,"permalink":"/tags/microsoft-teams/","section":"Tags","summary":"","title":"Microsoft Teams","type":"tags"},{"content":"","date":"20 January 2025","externalUrl":null,"permalink":"/tags/ollama/","section":"Tags","summary":"","title":"Ollama","type":"tags"},{"content":"","date":"20 January 2025","externalUrl":null,"permalink":"/tags/teams-app-test-tool/","section":"Tags","summary":"","title":"Teams App Test Tool","type":"tags"},{"content":"","date":"20 January 2025","externalUrl":null,"permalink":"/tags/teams-toolkit/","section":"Tags","summary":"","title":"Teams Toolkit","type":"tags"},{"content":"","date":"12 January 2025","externalUrl":null,"permalink":"/tags/devcontainer/","section":"Tags","summary":"","title":"DevContainer","type":"tags"},{"content":"","date":"12 January 2025","externalUrl":null,"permalink":"/tags/devops/","section":"Tags","summary":"","title":"DevOps","type":"tags"},{"content":"To conclude this series on using UV for developing Python projects within a portable environment using containers, we will create a sample project and experiment with UV.\nIn our scenario, we will keep it simple. Our requirement is as follows: A store needs an API to return a list of products and filter these products by availability.\nTo get started, we need to set up our project and install the necessary dependencies. We will use FastAPI to create our API and Ruff as a linter to ensure code quality. Follow the steps below to initialize the project, install dependencies, and run the application.\nSteps to Follow: # Create the project. Install dependencies (FastAPI \u0026amp; uvicorn ). Install the linter (Ruff). Run the application. Explore the project structure and files. Create the Project # Run the command to initialize the project:\nuv init Store_api Explore the Project Structure # UV will create a project folder for us. It will generate the .gitignore file to manage which files or folders will be included or excluded from being pushed to our repository, .Python-version which mentions the global version of Python used, a hello world Python script, but the most important file here is pyproject.toml, which defines the project\u0026rsquo;s behavior and definition. pyproject.toml # [project] name = \u0026#34;store-api\u0026#34; version = \u0026#34;0.1.0\u0026#34; description = \u0026#34;Add your description here\u0026#34; readme = \u0026#34;README.md\u0026#34; requires-python = \u0026#34;\u0026gt;=3.12\u0026#34; dependencies = [] The pyproject.toml file specifies the required Python version for the project and lists the dependencies. Currently, the dependencies list is empty.\nAdd Dependencies (FastAPI \u0026amp; uvicorn) # As mentioned, we need FastAPI to create our API. To install the packages, navigate to the root project folder and run the following command:\nuv add fastapi uvicorn As you can see, it was so fast.\nTo quickly test the application, simply replace the content of hello.py with the following:\nfrom fastapi import FastAPI from typing import List, Optional from pydantic import BaseModel import uvicorn # Pydantic model for product response class ProductResponse(BaseModel): id: int name: str available: bool # Product class for internal data representation class Product: def __init__(self, id: int, name: str, available: bool): self.id = id self.name = name self.available = available # Sample products products = [ Product(1, \u0026#34;Jolly Jester Clown Wig\u0026#34;, True), Product(2, \u0026#34;Bozo the Clown Nose\u0026#34;, False), Product(3, \u0026#34;Circus Performer Clown Shoes\u0026#34;, True), Product(4, \u0026#34;Red Balloon Animal Kit\u0026#34;, True), Product(5, \u0026#34;Funny Clown Face Paint Set\u0026#34;, True), Product(6, \u0026#34;Mini Clown Horn\u0026#34;, False), Product(7, \u0026#34;Rainbow Clown Costume\u0026#34;, True), Product(8, \u0026#34;Clown Magician Hat\u0026#34;, True), Product(9, \u0026#34;Giggles the Clown Plush Doll\u0026#34;, True), Product(10, \u0026#34;Clown Comedy Seltzer Bottle\u0026#34;, False) ] # FastAPI app initialization app = FastAPI() @app.get(\u0026#34;/products\u0026#34;, response_model=List[ProductResponse]) def get_products(available: Optional[bool] = None): # If \u0026#39;available\u0026#39; query param is provided, filter products by availability filtered_products = products if available is None else [product for product in products if product.available == available] # Return products as list of Pydantic model instances return [ProductResponse(**product.__dict__) for product in filtered_products] @app.get(\u0026#34;/\u0026#34;) def main(): return {\u0026#34;message\u0026#34;: \u0026#34;Hello from store-api!\u0026#34;} if __name__ == \u0026#34;__main__\u0026#34;: uvicorn.run(app, host=\u0026#34;0.0.0.0\u0026#34;, port=8000) #main() # to run using command line `uv run uvicorn hello:app --port 8000` Installing and Using Tool (Ruff) # Every project needs some tooling like Ruff for linting. We can manage that by adding the tool as a dev dependency using uv add --dev ruff or just use uvx. Run the Application # To run the application, just use:\nuv run hello.py Click on the \u0026ldquo;Open in Browser\u0026rdquo; button from the popup. We don\u0026rsquo;t need to make any additional configuration for port forwarding. UV also creates and manages the .venv folder for us. upgrade / downgrade Python in a project # To upgrade or downgrade the Python version, simply update the version in the pyproject.toml file and run\nuv sync If you remember, we configured our initial environment to use Python 3.12, but we can use any version in our project. We don\u0026rsquo;t need to manage installation or set up multiple Python versions ‚Äî UV does the job for us.\nIn this post, we have successfully set up a Python project using UV, ensuring that we can go live with our container and start our productive approach with Dev Containers.\nYou can find the complete source code for this demo on GitHub. If you‚Äôre a fan of Dockerfiles and prefer to manage your development environment manually, refer to this project, which uses the official UV Dockerfile definition.\nCheers! üçª\n","date":"12 January 2025","externalUrl":null,"permalink":"/posts/2025-01-12-getting-started-with-uv-in-docker-step-3-explained/","section":"Posts","summary":"","title":"Getting Started with UV in Docker","type":"posts"},{"content":"","date":"12 January 2025","externalUrl":null,"permalink":"/tags/podman/","section":"Tags","summary":"","title":"Podman","type":"tags"},{"content":"","date":"12 January 2025","externalUrl":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"","date":"12 January 2025","externalUrl":null,"permalink":"/tags/vscode/","section":"Tags","summary":"","title":"VSCode","type":"tags"},{"content":"","date":"12 January 2025","externalUrl":null,"permalink":"/tags/wsl/","section":"Tags","summary":"","title":"WSL","type":"tags"},{"content":"In our series exploring how to set up a streamlined and organized way to start your Python development journey using the DevContainer VSCode extension and Docker (or WSL/Podman), we\u0026rsquo;ve already seen how simple it is to define our development environment using just the DevContainer extension. Now, we\u0026rsquo;re ready to move on to the next part of the series: Optimize Python Development with VSCode and Docker.\nRunning Our Environment for the First Time # In this post, we will run our development environment for the first time and start working with Python using an amazing package and project manager, uv.\nAfter generating the definition for our environment, we now have a devcontainer.json file structure. Let‚Äôs dig in to explore what we have in this setup:\nBreaking Down the devcontainer.json Structure # Image Section:\nThis section specifies the container image reference, which is hosted on the Microsoft Container Registry.\nNote: You can also use a local image if you prefer. use DockerFile or Docker compose file.\nFeatures Section:\nThink of this section as a way to enhance the environment with additional tools and packages. In our case, we‚Äôre using uv (with shellautocompletion option enbaled).\ncustomization Section: The customization section is used to fine-tune the container development environment. It allows us to install additional extensions that will only be loaded inside the container, apply specific settings related to VSCode preferences, and execute additional commands.\nFor more information on available features, visit the Dev Containers Features Documentation. # If you\u0026rsquo;re working with a rootless container, you can find relevant information. here.\nLaunching Our Environment for the First Time üöÄ # Now it\u0026rsquo;s time to launch our environment for the first time! To do this, simply click on the Dev Container icon and choose Reopen in Container.\nIn the background:\nAn image will be added to your Docker images list. A container should be running. A volume will be created. VSCode will reload, but this time, it will run under the container. Time to Verify # The Remote Indicator in the status bar will display additional information, such as the name of the container we\u0026rsquo;re currently in and the distribution of the image being used.\nVerifying Python Version and Testing uv # Let‚Äôs perform a couple more checks by verifying the Python version being used and testing if uv is running correctly.\nEverything seems good so far! The next step is to create our first project and run it. That‚Äôs exactly what we‚Äôll cover in the next post.\nStay tuned!\n","date":"8 January 2025","externalUrl":null,"permalink":"/posts/2025-01-08-streamline-python-development-in-devcontainer-with-uv/","section":"Posts","summary":"","title":"Streamline Python Development in DevContainer with UV","type":"posts"},{"content":"In today\u0026rsquo;s world, Python is used for many purposes in large projects, especially in AI, LLM, and RAG. However, maintaining a healthy environment, managing compatibility, and handling packaging can be challenging tasks.\nFor this reason, using containers not only for deploying Python apps but also as a development environment could be a suitable approach.\nIn this post, we will show how simple it is to start developing Python projects without needing to install Python, manage multiple versions, create virtual environments, set environment variables, and handle other prerequisites.\nWe can achieve this directly from VSCode using just one extension.\nPresenting the Extension # We‚Äôve probably all seen the .devcontainer folder and the devcontainer.json file in other projects. But what do they do?\nThe .devcontainer folder and its JSON file are used to define a containerized development environment. This setup ensures that all developers on a project have a consistent development environment, regardless of their local machine configurations. The .devcontainer configuration can specify the base image, extensions, and settings needed for the project.\nWe‚Äôre going to make this easy by generating the configuration files automatically‚Äîno need to craft them manually from scratch! üòâ\nSo let\u0026rsquo;s get started\u0026hellip;\nPrerequisites # Before we dive in, make sure we have Docker and VSCode installed.\nStep 1: Installing the Extension # First, let‚Äôs install the necessary extension in VSCode. We can do this by visiting the Dev Container extension page or by searching for it directly in the extension manager in Visual Studio Code. Use the Ctrl+Shift+X shortcut to open the extension manager.\nStep 2: Generate the DevContainer Folder # After installing the extension, we should find an icon at the bottom left side of our IDE. Click on it and follow the wizard steps to generate the .devcontainer folder and configuration files.\nSelect Add Dev Container Configuration Files.\nThen select Add Configuration to Workspace. This will add the .devcontainer folder and related configuration to our current project directory.\nWe can choose from a variety of preset configurations. In our case, we will select Python 3.\nWe‚Äôll be prompted to choose the Python version for your container. Pick any version you‚Äôre comfortable with (we‚Äôll go with Python 3.12 bullseye).\nIn the following step, we can choose additional features. We‚Äôll select uv, a great package and project manager that we‚Äôll use further in this post.\nWe can also select additional configurations for the features, so let‚Äôs enable the shell autocompletion option.\nWe can skip the next step if we don\u0026rsquo;t want to use the Dependabot functionality. Dependabot helps us keep our dependencies up to date by automatically checking for updates and creating pull requests. After running the wizard, we‚Äôll end up with the following root project structure.\nüéâ Once the .devcontainer folder is set up, there‚Äôs no need to build an image manually‚Äîthe extension will handle that for us! We‚Äôre now ready to connect to the containerized environment and start using it as our development environment. We‚Äôll explore this process in Part 2 of this post, so stay tuned!\nHappy coding, and see you in the next part!\n","date":"5 January 2025","externalUrl":null,"permalink":"/posts/2025-01-05-optimize-python-development-with-docker/","section":"Posts","summary":"","title":"Optimize Python Development with VSCode and Docker","type":"posts"},{"content":"","date":"5 January 2025","externalUrl":null,"permalink":"/tags/aboutme/","section":"Tags","summary":"","title":"Aboutme","type":"tags"},{"content":"","date":"5 January 2025","externalUrl":null,"permalink":"/tags/agentifyanchor/","section":"Tags","summary":"","title":"Agentifyanchor","type":"tags"},{"content":"Hello! üëã I am the firend of Moh. D üòÅ and I love eating üçïüçïüçï\nI\u0026rsquo;m a Microsoft Specialist üíª with a deep passion for AI ü§ñ. Over the years, I\u0026rsquo;ve become fascinated by optimizing development environments, especially in the world of Python üêç, Docker üêã, and VSCode üñ•Ô∏è. I‚Äôm always looking for ways to simplify complex tasks and make development smoother, which is why I love using containers and powerful tools to create consistent and portable setups.\nMy journey is all about exploring new technologies, automating workflows, and applying AI in innovative ways. I‚Äôm excited to share my insights and experiences with you, and I hope to learn and grow together in this tech journey! üåü\nDon\u0026rsquo;t forget to follow me on Twitter. üê¶ ","date":"5 January 2025","externalUrl":null,"permalink":"/posts/discover-journey/","section":"Posts","summary":"","title":"Discover My Journey: About Me","type":"posts"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]